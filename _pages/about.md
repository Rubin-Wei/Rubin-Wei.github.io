---
permalink: /
title: ""
excerpt: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

# ğŸ‘‹ About Me

Iâ€™m a first-year Ph.D. student in Computer Science at the [School of Artificial Intelligence, Shanghai Jiao Tong University (SJTU)](https://soai.sjtu.edu.cn/), advised by Prof. [Zhouhan Lin](https://hantek.github.io/). Previously, I received my B.E. in Information Security from [Wuhan University](https://www.whu.edu.cn/).

My research interests lie in machine learning and large language models (LLMs), particularly in:
- Memory-augmented LLMs â€” training long-term memory to retain the entire training dataset  
- Parametric retrieval architectures for efficient and adaptive knowledge access  
- Decoupling common and factual knowledge within LLMs  

Iâ€™m always open to discussions and collaborations â€” feel free to reach out if youâ€™d like to chat!

## ğŸ”¥ <a id="news"></a>News

- **2025.09** ğŸ‰ğŸ‰ *MemoryDecoder* accepted to **NeurIPS 2025**  
- **2025.06** ğŸ†ğŸ† My undergraduate thesis was selected as an *Outstanding Thesis*  
- **2024.12** ğŸ‰ğŸ‰ One paper accepted to **IEEE TIFS 2024**  
- **2024.06** ğŸ‰ğŸ‰ *Beowulf* accepted to **ACM CCS 2024**


## ğŸ“š <a id="publications"></a>Publications

1. **MLP Memory: A Retriever-Pretrained Memory for Large Language Models**  
   ***Rubin Wei**\*, Jiaqi Cao\*, Jiarui Wang, Jushi Kai, Qipeng Guo, Bowen Zhou, Zhouhan Lin*  
   _Preprint (2025)_  
   ğŸ”— [arXiv](https://arxiv.org/abs/2508.01832) Â· [GitHub](https://github.com/Rubin-Wei/MLPMemory) Â· [HuggingFace](https://huggingface.co/collections/Rubin-Wei/mlpmemory) Â· \* Equal Contribution

2. **Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models**  
   *Jiaqi Cao\*, Jiarui Wang\*, **Rubin Wei**, Qipeng Guo, Kai Chen, Bowen Zhou, Zhouhan Lin*  
   _NeurIPS 2025 Poster_  
   ğŸ”— [arXiv](https://arxiv.org/abs/2508.09874) Â· [GitHub](https://github.com/LUMIA-Group/MemoryDecoder) Â· [HuggingFace](https://huggingface.co/collections/Clover-Hill/memorydecoder) Â· \* Equal Contribution

3. **Beowulf: Mitigating Model Extraction Attacks via Reshaping Decision Regions**  
   *Xueluan Gong, Rubin Wei, Ziyao Wang, Yuchen Sun, Jiawen Peng, Yanjiao Chen, Qian Wang*  
   _ACM CCS 2024_  
   ğŸ”— [ACM DL](https://dl.acm.org/doi/abs/10.1145/3658644.3670267)

4. **Augmenting Model Extraction Attacks Against Disruption-Based Defenses**  
   *Xueluan Gong, Shuaike Li, Yanjiao Chen, Mingzhe Li, Rubin Wei, Qian Wang, Kwok-Yan Lam*  
   _IEEE Transactions on Information Forensics & Security (TIFS) 2024_  
   ğŸ”— [IEEE Xplore](https://ieeexplore.ieee.org/abstract/document/10793405)

## ğŸ“ <a id="education"></a>Education

- *2025.09â€“Present*, Ph.D. Student, [School of Artificial Intelligence](https://soai.sjtu.edu.cn/), [Shanghai Jiao Tong University](https://www.sjtu.edu.cn/)
- *2021.09â€“2025.06*, B.E. in Information Security,[ School of Cyber Science and Engineering](https://cse.whu.edu.cn/), [Wuhan University](https://www.whu.edu.cn/)


## ğŸ’¼ <a id="internships"></a>Internships

- *2024.11â€“2025.02*, [TeleAI](https://www.teleai.com.cn/), Shanghai, China
- *2024.04â€“2025.06*, [Shanghai AI Lab](https://www.shlab.org.cn/), Shanghai, China


## ğŸ… Honors and Awards

- National Scholarship, 2023
- Outstanding Undergraduate Thesis Award, 2025




<!-- ---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Iâ€™m a first-year Ph.D. student in Computer Science at SJTUäººå·¥æ™ºèƒ½å­¦é™¢, focusing on machine learning, particularly large language models. I am fortunate to be advised by Prof. Zhouhan Lin. Previously, æˆ‘æ¯•ä¸šäºæ­¦æ±‰å¤§å­¦ä¿¡æ¯å®‰å…¨ä¸“ä¸š.

Iâ€™m currently interested in memory-augemented large language models, including traing a long-term memory to memorize the whole training dataset, å¸¦æœ‰å‚æ•°åŒ–æ£€ç´¢çš„æ–°æ¶æ„æ¨¡å‹. And è‡´åŠ›äºå°†LLMå½“ä¸­çš„common knowledge and factual knowkedge decoupled. I'm always happy to connect, so feel free to reach out for a chat or collaboration.



## <a id="news"></a>News
2025.09  ğŸ‰ğŸ‰ MemoryDecoder is accepeted to NeurIPS 2025.
2025.06  ğŸ‰ğŸ‰ æˆ‘çš„æ¯•ä¸šè®¾è®¡è¢«è¯„é€‰ä¸ºä¼˜ç§€è®ºæ–‡.
2024.12:  ğŸ‰ğŸ‰ 1 paper is accepted to TIFS 2024.
2024.6:  ğŸ‰ğŸ‰ Beowulf is accepted to ACM 2024.


## <a id="publications"></a>Publications
1. 
æ ‡é¢˜ï¼šMLP Memory: A Retriever-Pretrained Memory for Large Language Models
é“¾æ¥ï¼šhttps://arxiv.org/abs/2508.01832
ä½œè€…ï¼šRubin Wei, Jiaqi Cao, Jiarui Wang, Jushi Kai, Qipeng Guo, Bowen Zhou, Zhouhan Lin
çŠ¶æ€ï¼šPreprint
Githubï¼šhttps://github.com/Rubin-Wei/MLPMemory
Huggingface: https://huggingface.co/collections/Rubin-Wei/mlpmemory
å¹´ä»½ï¼š2025
2. 
æ ‡é¢˜ï¼šMemory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models
é“¾æ¥ï¼šhttps://arxiv.org/abs/2508.09874
ä½œè€…ï¼šJiaqi Cao, Jiarui Wang, Rubin Wei, Qipeng Guo, Kai Chen, Bowen Zhou, Zhouhan Lin
çŠ¶æ€ï¼šNeurIPS 2025 Poster
Githubï¼šhttps://github.com/LUMIA-Group/MemoryDecoder
Huggingface: https://huggingface.co/collections/Clover-Hill/memorydecoder
å¹´ä»½ï¼š2025
3. 
æ ‡é¢˜ï¼šBeowulf: Mitigating Model Extraction Attacks Via Reshaping Decision Regions
é“¾æ¥ï¼šhttps://dl.acm.org/doi/abs/10.1145/3658644.3670267
ä½œè€…ï¼šXueluan Gong, Rubin Wei, Ziyao Wang, Yuchen Sun, Jiawen Peng, Yanjiao Chen, Qian Wang
çŠ¶æ€ï¼šACM Conference on Computer and Communications Security (CCS) 2024
å¹´ä»½ï¼š2024
4. 
æ ‡é¢˜ï¼šAugmenting Model Extraction Attacks Against Disruption-Based Defenses
é“¾æ¥ï¼šhttps://ieeexplore.ieee.org/abstract/document/10793405
ä½œè€…ï¼šXueluan Gong, Shuaike Li, Yanjiao Chen, Mingzhe Li, Rubin Wei, Qian Wang, Kwok-Yan Lam
çŠ¶æ€ï¼šTransactions on Information Forensics & Security (TIFS) 2024


## <a id="education"></a>Education
1. 2025.09 - Present, Ph.D Student, äººå·¥æ™ºèƒ½å­¦é™¢, ä¸Šæµ·äº¤é€šå¤§å­¦
2. 2021.09 - 2025.06, Undergraduate, School of Cyber Science and Engineering, Wuhan University

## <a id="internships"></a>Internships
1. 2024.11 - 2025.02, TeleAI, Shanghai, China.
2. 2024.04 - 2025.06, Shanghai AI Lab, Shanghai, China.


# Honors and Awards
æœ¬ç§‘ä¼˜ç§€è®ºæ–‡
å›½å®¶å¥–å­¦é‡‘


 -->
